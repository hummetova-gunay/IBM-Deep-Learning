{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd3296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NN: 2 inputs, hidden layer, with 2 neurons, 1 output\n",
    "#  6 weights, 3 biases, 3 weighted sums, 3 activation functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc61ee3",
   "metadata": {},
   "source": [
    "### Inputs, Weights, Biases, Weighted Sums, Activation Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a24b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights [0.16 0.48 0.89 0.54 0.74 0.75]\n",
      "Biases [0.49 0.66 0.69]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#  randomly initialize biases\n",
    "weights =np.round(np.random.uniform(size = 6), decimals=2) \n",
    "biases = np.round(np.random.uniform(size = 3), decimals= 2)\n",
    "\n",
    "print(f'Weights {weights}')\n",
    "print(f'Biases {biases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a86040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum 1: 0.978\n",
      "Weighted sum 2: 1.564\n"
     ]
    }
   ],
   "source": [
    "#  inputs  and weighted sums\n",
    "x_1 = 0.5\n",
    "x_2 = 0.85\n",
    "\n",
    "z_11 = x_1*weights[0] + x_2* weights[1] + biases[0]\n",
    "z_12 = x_1 *weights[2] + x_2* weights[3] + biases[1]\n",
    "\n",
    "print(f'Weighted sum 1: {z_11}')\n",
    "print(f'Weighted sum 2: {z_12}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f1e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7267111924225421\n",
      "0.82692657787722\n"
     ]
    }
   ],
   "source": [
    "#  activation functions in the  hidden layer\n",
    "a_11 = 1/(1+np.exp(-z_11))\n",
    "a_12 = 1/(1+np.exp(-z_12))\n",
    "print(a_11)\n",
    "print(a_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e6f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8479612158005962\n"
     ]
    }
   ],
   "source": [
    "# weighted sum in the output layer\n",
    "z_2 = a_11*weights[4] + a_12*weights[5] + biases[2]\n",
    "print(z_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071caea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863887548619393\n"
     ]
    }
   ],
   "source": [
    "# activation function in the output layer\n",
    "a_2 = 1/(1+np.exp(-z_2))\n",
    "print(a_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabac4b3",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b7a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # number of inputs\n",
    "num_hidden_layers = 2 # number of hidden layers\n",
    "m = [2, 2] # number of nodes in each hidden layer\n",
    "num_nodes_output = 1 # number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4867e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.26, 0.76]), 'bias': array([0.02])}, 'node_2': {'weights': array([0.17, 0.82]), 'bias': array([0.43])}}, 'layer_2': {'node_1': {'weights': array([0.74, 0.44]), 'bias': array([0.96])}, 'node_2': {'weights': array([0.17, 0.11]), 'bias': array([0.7])}}, 'output': {'node_1': {'weights': array([0.15, 0.81]), 'bias': array([0.15])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import the Numpy library\n",
    "\n",
    "num_nodes_previous = n # number of nodes in the previous layer\n",
    "\n",
    "network = {} # initialize network an an empty dictionary\n",
    "\n",
    "# loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# notice how we are adding 1 to the number of hidden layers in order to include the output layer\n",
    "for layer in range(num_hidden_layers + 1): \n",
    "    \n",
    "    # determine name of layer\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) # print network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2876c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs # number of nodes in the previous layer\n",
    "\n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dbd00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small network with 5 inputs, 3 hidden layers, 3 nodes in the first layer, 2nodes in the second and 3 nodes in the third layer, 1 node in the output\n",
    "small_network = initialize_network(5, 3, [3,2,3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ce6fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': {'node_1': {'weights': array([0.73, 0.94, 0.03, 0.19, 0.72]),\n",
       "   'bias': array([0.6])},\n",
       "  'node_2': {'weights': array([0.34, 0.46, 0.31, 0.98, 0.67]),\n",
       "   'bias': array([0.88])},\n",
       "  'node_3': {'weights': array([0.05, 0.83, 0.67, 0.76, 0.35]),\n",
       "   'bias': array([0.15])}},\n",
       " 'layer_2': {'node_1': {'weights': array([0.49, 0.35, 0.27]),\n",
       "   'bias': array([0.77])},\n",
       "  'node_2': {'weights': array([0.22, 0.15, 0.4 ]), 'bias': array([0.56])}},\n",
       " 'layer_3': {'node_1': {'weights': array([0.77, 0.51]), 'bias': array([0.72])},\n",
       "  'node_2': {'weights': array([0.82, 0.4 ]), 'bias': array([0.82])},\n",
       "  'node_3': {'weights': array([0.18, 0.82]), 'bias': array([0.49])}},\n",
       " 'output': {'node_1': {'weights': array([0.71, 0.72, 0.04]),\n",
       "   'bias': array([0.25])}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6178ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, biases):\n",
    "    return np.sum(inputs*weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de531b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37, 0.95, 0.73, 0.6 , 0.16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  generate 5 inputs to feed small_network\n",
    "from random import seed\n",
    "np.random.seed(42)\n",
    "\n",
    "inputs = np.around(np.random.uniform(size=5), decimals = 2)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e07b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9042, 2.0742, 2.1042])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute weighted sum in the first node, at the first layer\n",
    "node_weights = small_network['layer_1']['node_1']['weights']\n",
    "node_bias = small_network['layer_1']['node_1']['bias']\n",
    "\n",
    "weighted_sum = compute_weighted_sum(inputs,node_weights, biases)\n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a546127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute node activation\n",
    "def node_activation(weighted_sum):\n",
    "    return 1/(1+np.exp(-1* weighted_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1831ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87036614, 0.88837015, 0.89131073])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_output = node_activation(weighted_sum)\n",
    "node_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f54ae0",
   "metadata": {},
   "source": [
    "### Forward Propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be02a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "        \n",
    "            # compute the weighted sum and the output of each node at the same time \n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721bef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [np.float64(0.8823), np.float64(0.9141), np.float64(0.8763)]\n",
      "The outputs of the nodes in hidden layer number 2 is [np.float64(0.8531), np.float64(0.7759)]\n",
      "The outputs of the nodes in hidden layer number 3 is [np.float64(0.8548), np.float64(0.8618), np.float64(0.7824)]\n"
     ]
    }
   ],
   "source": [
    "predictions =forward_propagate(small_network, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "819677c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8189)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d8c4b",
   "metadata": {},
   "source": [
    "Deep learning is one of the hottest subjects in data science. \n",
    "\n",
    "Color restoration applications can automatically convert a grayscale image into a colored image. \n",
    "\n",
    "Speech enactment applications can synthesize audio clips with lip movements in videos, extracting audio from one video and syncing its lip movements with the audio from another video. \n",
    "\n",
    "Handwriting generation applications can rewrite a provided message in highly realistic cursive handwriting in a wide variety of styles. \n",
    "\n",
    "Deep learning algorithms are largely inspired by the way neurons and neural networks function and process data in the brain. \n",
    "\n",
    "The main body of a neuron is the soma, and the extensive network of arms that stick out of the body are called dendrites. The long arm that sticks out of the soma in the other direction is called the axon.  \n",
    "\n",
    "Whiskers at the end of the axon are called the synapses.  \n",
    "\n",
    "Dendrites receive electrical impulses that carry information from synapses of other adjoining neurons. Dendrites carry the impulses to the soma.  \n",
    "\n",
    "In the nucleus, electrical impulses are processed by combining them, and then they are passed on to the axon. The axon carries the processed information to the synapses, and the output of this neuron becomes the input to thousands of other neurons. \n",
    "\n",
    "Learning in the brain occurs by repeatedly activating certain neural connections over others, and this reinforces those connections. \n",
    "\n",
    "An artificial neuron behaves in the same way as a biological neuron. \n",
    "\n",
    "The first layer that feeds input into the neural network is the input layer. \n",
    "\n",
    "The set of nodes that provide network output is the output layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
